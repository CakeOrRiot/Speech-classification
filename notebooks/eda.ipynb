{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>READER</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>SUBSET NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>M</td>\n",
       "      <td>train-clean-360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>F</td>\n",
       "      <td>train-other-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>8975</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>9000</td>\n",
       "      <td>M</td>\n",
       "      <td>train-other-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>9022</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>9023</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>9026</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2484 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      READER GENDER      SUBSET NAME\n",
       "0         14      F  train-clean-360\n",
       "1         16      F  train-clean-360\n",
       "2         17      M  train-clean-360\n",
       "3         19      F  train-clean-100\n",
       "4         20      F  train-other-500\n",
       "...      ...    ...              ...\n",
       "2479    8975      F  train-clean-100\n",
       "2480    9000      M  train-other-500\n",
       "2481    9022      F  train-clean-360\n",
       "2482    9023      F  train-clean-360\n",
       "2483    9026      F  train-clean-360\n",
       "\n",
       "[2484 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root = Path('../data/')\n",
    "df=pd.read_csv(data_root/'processed'/'speakers.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    1283\n",
       "F    1201\n",
       "Name: GENDER, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['GENDER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from python_speech_features import logfbank\n",
    "# from python_speech_features import mfcc\n",
    "# from python_speech_features import delta\n",
    "import scipy.io.wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/maksim/Desktop/internship/2022/huawei/Speech-recognition/notebooks/eda.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/maksim/Desktop/internship/2022/huawei/Speech-recognition/notebooks/eda.ipynb#ch0000005?line=0'>1</a>\u001b[0m audio \u001b[39m=\u001b[39m wav\u001b[39m.\u001b[39mread(data_root\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpreprocessed\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39maudio\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m84_121123_000008_000001.wav\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/maksim/Desktop/internship/2022/huawei/Speech-recognition/notebooks/eda.ipynb#ch0000005?line=1'>2</a>\u001b[0m audio\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/maksim/Desktop/internship/2022/huawei/Speech-recognition/notebooks/eda.ipynb#ch0000005?line=2'>3</a>\u001b[0m pd\u001b[39m.\u001b[39;49mread\n",
      "File \u001b[0;32m~/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/pandas/__init__.py:261\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/pandas/__init__.py?line=256'>257</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m SparseArray \u001b[39mas\u001b[39;00m _SparseArray\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/pandas/__init__.py?line=258'>259</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _SparseArray\n\u001b[0;32m--> <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/pandas/__init__.py?line=260'>261</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpandas\u001b[39m\u001b[39m'\u001b[39m\u001b[39m has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "audio = wav.read(data_root/'processed'/'audio'/'84_121123_000008_000001.wav')\n",
    "audio\n",
    "pd.read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1086, 13)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from python_speech_features import mfcc\n",
    "from python_speech_features import logfbank\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "(rate,sig) = wav.read(data_root/'processed'/'audio' / \"1673_143396_000014_000007.wav\")\n",
    "mfcc_feat = mfcc(sig,rate,nfft=1024)\n",
    "# fbank_feat = logfbank(sig,rate)\n",
    "# \n",
    "# print(fbank_feat[1:3,:])\n",
    "mfcc_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((419, 13), (419, 26))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_feat.shape,fbank_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-309.3644   ,   91.03992  ,  -30.265484 ,   18.281233 ,\n",
       "         -3.109729 ,  -12.469646 ,  -13.716736 ,  -20.54444  ,\n",
       "        -11.392519 ,   -4.953721 ,  -13.70659  ,    5.2050285,\n",
       "         -2.3841207,    1.0798869,    2.0913243,    1.6696934,\n",
       "         -5.872282 ,   -2.311453 ,   -6.7171226,   -0.9657522],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "signal, sr = librosa.load(data_root / \"processed\" / \"audio\" / '8842_302201_000014_000005.wav')\n",
    "mfccs = librosa.feature.mfcc(y=signal, sr=sr)\n",
    "mfccs.mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '../data/processed/audio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py:155\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py?line=152'>153</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py?line=153'>154</a>\u001b[0m     \u001b[39m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py?line=154'>155</a>\u001b[0m     context \u001b[39m=\u001b[39m sf\u001b[39m.\u001b[39;49mSoundFile(path)\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py?line=156'>157</a>\u001b[0m \u001b[39mwith\u001b[39;00m context \u001b[39mas\u001b[39;00m sf_desc:\n",
      "File \u001b[0;32m~/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/soundfile.py:629\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/soundfile.py?line=626'>627</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info \u001b[39m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/soundfile.py?line=627'>628</a>\u001b[0m                                  \u001b[39mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/soundfile.py?line=628'>629</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(file, mode_int, closefd)\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/soundfile.py?line=629'>630</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mset\u001b[39m(mode)\u001b[39m.\u001b[39missuperset(\u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseekable():\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/soundfile.py?line=630'>631</a>\u001b[0m     \u001b[39m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/soundfile.py:1183\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/soundfile.py?line=1181'>1182</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid file: \u001b[39m\u001b[39m{0!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname))\n\u001b[0;32m-> <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/soundfile.py?line=1182'>1183</a>\u001b[0m _error_check(_snd\u001b[39m.\u001b[39;49msf_error(file_ptr),\n\u001b[1;32m   <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/soundfile.py?line=1183'>1184</a>\u001b[0m              \u001b[39m\"\u001b[39;49m\u001b[39mError opening \u001b[39;49m\u001b[39m{0!r}\u001b[39;49;00m\u001b[39m: \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname))\n\u001b[1;32m   <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/soundfile.py?line=1184'>1185</a>\u001b[0m \u001b[39mif\u001b[39;00m mode_int \u001b[39m==\u001b[39m _snd\u001b[39m.\u001b[39mSFM_WRITE:\n\u001b[1;32m   <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/soundfile.py?line=1185'>1186</a>\u001b[0m     \u001b[39m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/soundfile.py?line=1186'>1187</a>\u001b[0m     \u001b[39m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/soundfile.py?line=1187'>1188</a>\u001b[0m     \u001b[39m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/soundfile.py:1357\u001b[0m, in \u001b[0;36m_error_check\u001b[0;34m(err, prefix)\u001b[0m\n\u001b[1;32m   <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/soundfile.py?line=1355'>1356</a>\u001b[0m err_str \u001b[39m=\u001b[39m _snd\u001b[39m.\u001b[39msf_error_number(err)\n\u001b[0;32m-> <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/soundfile.py?line=1356'>1357</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(prefix \u001b[39m+\u001b[39m _ffi\u001b[39m.\u001b[39mstring(err_str)\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mreplace\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error opening '../data/processed/audio': File contains data in an unknown format.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/maksim/Desktop/internship/2022/huawei/Speech-recognition/notebooks/eda.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/maksim/Desktop/internship/2022/huawei/Speech-recognition/notebooks/eda.ipynb#ch0000011?line=0'>1</a>\u001b[0m librosa\u001b[39m.\u001b[39;49mload(data_root \u001b[39m/\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mprocessed\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m/\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39maudio\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/util/decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/util/decorators.py?line=85'>86</a>\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[1;32m     <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/util/decorators.py?line=86'>87</a>\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/util/decorators.py?line=87'>88</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/util/decorators.py?line=89'>90</a>\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/util/decorators.py?line=90'>91</a>\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/util/decorators.py?line=91'>92</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[1;32m     <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/util/decorators.py?line=92'>93</a>\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[1;32m     <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/util/decorators.py?line=93'>94</a>\u001b[0m ]\n",
      "File \u001b[0;32m~/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py:174\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py?line=171'>172</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, (\u001b[39mstr\u001b[39m, pathlib\u001b[39m.\u001b[39mPurePath)):\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py?line=172'>173</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[39m\"\u001b[39m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py?line=173'>174</a>\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __audioread_load(path, offset, duration, dtype)\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py?line=174'>175</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py?line=175'>176</a>\u001b[0m     \u001b[39mraise\u001b[39;00m (exc)\n",
      "File \u001b[0;32m~/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py:198\u001b[0m, in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py?line=191'>192</a>\u001b[0m \u001b[39m\"\"\"Load an audio buffer using audioread.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py?line=192'>193</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py?line=193'>194</a>\u001b[0m \u001b[39mThis loads one block at a time, and then concatenates the results.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py?line=194'>195</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py?line=196'>197</a>\u001b[0m y \u001b[39m=\u001b[39m []\n\u001b[0;32m--> <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py?line=197'>198</a>\u001b[0m \u001b[39mwith\u001b[39;00m audioread\u001b[39m.\u001b[39;49maudio_open(path) \u001b[39mas\u001b[39;00m input_file:\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py?line=198'>199</a>\u001b[0m     sr_native \u001b[39m=\u001b[39m input_file\u001b[39m.\u001b[39msamplerate\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/librosa/core/audio.py?line=199'>200</a>\u001b[0m     n_channels \u001b[39m=\u001b[39m input_file\u001b[39m.\u001b[39mchannels\n",
      "File \u001b[0;32m~/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/audioread/__init__.py:111\u001b[0m, in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/audioread/__init__.py?line=108'>109</a>\u001b[0m \u001b[39mfor\u001b[39;00m BackendClass \u001b[39min\u001b[39;00m backends:\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/audioread/__init__.py?line=109'>110</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/audioread/__init__.py?line=110'>111</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m BackendClass(path)\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/audioread/__init__.py?line=111'>112</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m DecodeError:\n\u001b[1;32m    <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/audioread/__init__.py?line=112'>113</a>\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/audioread/rawread.py:62\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/audioread/rawread.py?line=60'>61</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, filename):\n\u001b[0;32m---> <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/audioread/rawread.py?line=61'>62</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/audioread/rawread.py?line=63'>64</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/maksim/Desktop/internship/2022/huawei/Speech-recognition/venv/lib/python3.8/site-packages/audioread/rawread.py?line=64'>65</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m aifc\u001b[39m.\u001b[39mopen(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh)\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '../data/processed/audio'"
     ]
    }
   ],
   "source": [
    "librosa.load(data_root / \"processed\" / \"audio\"/'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59c16bc9c82eddd4b088ab4788dc2ca2002d92db388f9d4fc374d09526621433"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
